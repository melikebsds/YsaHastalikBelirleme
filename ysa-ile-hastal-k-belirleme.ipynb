{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/nurmelike/ysa-ile-hastal-k-belirleme?scriptVersionId=94932522\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"import random\nimport cv2\n\n# verileri düzenleyebilmek değiştirebilmek için\nimport numpy as np\nimport pandas as pd\n\n# Derin öğrenme modelleri oluşturmak yönetmek için\nfrom keras import backend as K\nfrom keras.preprocessing import image\nfrom sklearn.metrics import roc_auc_score, roc_curve\n\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.densenet import DenseNet121\nfrom keras.layers import Dense, GlobalAveragePooling2D\nfrom keras.models import Model\n\nfrom keras.models import load_model\n\n\nfrom tensorflow.keras.applications import DenseNet121\nimport tensorflow as tf\nimport tensorflow.keras.layers as Layers\n\n# görselleştirme ve grafik için\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\n\nrandom.seed(a=None, version=2)\n\n\n# roc eğrisi elde etmek için\ndef get_roc_curve(labels, predicted_vals, generator, when = ''):\n    auc_roc_vals = []\n    for i in range(len(labels)):\n        try:\n            gt = generator.labels[:, i]\n            pred = predicted_vals[:, i]\n            auc_roc = roc_auc_score(gt, pred)\n            auc_roc_vals.append(auc_roc)\n            fpr_rf, tpr_rf, _ = roc_curve(gt, pred)\n            plt.figure(1, figsize=(10, 10))\n            plt.plot([0, 1], [0, 1], 'k--')\n            plt.plot(fpr_rf, tpr_rf,\n                     label=labels[i] + \" (\" + str(round(auc_roc, 3)) + \")\")\n            plt.xlabel('False positive rate')\n            plt.ylabel('True positive rate')\n            plt.title('ROC curve ' + when)\n            plt.legend(loc='best')\n        except:\n            print(\n                f\"Error in generating ROC curve for {labels[i]}. \"\n                f\"Dataset lacks enough examples.\"\n            )\n    plt.show()\n    return auc_roc_vals\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-12T19:48:26.418511Z","iopub.execute_input":"2022-01-12T19:48:26.418885Z","iopub.status.idle":"2022-01-12T19:48:32.634727Z","shell.execute_reply.started":"2022-01-12T19:48:26.418801Z","shell.execute_reply":"2022-01-12T19:48:32.634013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# tpu algılama kagglede\ntry:\n \n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    #cpu ve gpu için TF dağıtım stratejisi\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:32.636452Z","iopub.execute_input":"2022-01-12T19:48:32.636702Z","iopub.status.idle":"2022-01-12T19:48:32.65393Z","shell.execute_reply.started":"2022-01-12T19:48:32.636669Z","shell.execute_reply":"2022-01-12T19:48:32.653162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"IMAGE_SIZE=[128, 128]\nEPOCHS = 20\nBATCH_SIZE = 64\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:32.655176Z","iopub.execute_input":"2022-01-12T19:48:32.655447Z","iopub.status.idle":"2022-01-12T19:48:32.671674Z","shell.execute_reply.started":"2022-01-12T19:48:32.655411Z","shell.execute_reply":"2022-01-12T19:48:32.670902Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_df_main = pd.read_csv('../input/databinli/databinli.csv')\n\n\nlabels = train_df_main.columns[0:-1]\nlabels","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:32.672966Z","iopub.execute_input":"2022-01-12T19:48:32.673261Z","iopub.status.idle":"2022-01-12T19:48:32.748939Z","shell.execute_reply.started":"2022-01-12T19:48:32.673223Z","shell.execute_reply":"2022-01-12T19:48:32.748283Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# veri kümesini bölme işlemi\nfrom sklearn.model_selection import train_test_split\ntrain_df, discard = train_test_split(train_df_main, test_size = 0.3, random_state = 1993)\nprint(train_df)\nprint(\"@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@\")\nprint(discard)\n\ntrain_and_valid_set, test_set = train_test_split(train_df, test_size = 0.2, random_state = 1993)\ntrain_set, valid_set = train_test_split(train_and_valid_set, test_size = 0.2, random_state = 1993)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:32.751191Z","iopub.execute_input":"2022-01-12T19:48:32.751432Z","iopub.status.idle":"2022-01-12T19:48:32.809947Z","shell.execute_reply.started":"2022-01-12T19:48:32.751399Z","shell.execute_reply":"2022-01-12T19:48:32.80933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_train_generator(df, image_dir, x_col, y_cols, shuffle=True, batch_size=8, seed=1, target_w = 256, target_h = 256):\n    # \n    print(\"getting train generator...\")\n    # normalize images\n    image_generator = ImageDataGenerator(\n        samplewise_center=True,\n        samplewise_std_normalization= True, \n        shear_range=0.1,\n        zoom_range=0.15,\n        rotation_range=5,\n        width_shift_range=0.1,\n        height_shift_range=0.05,\n        horizontal_flip=True, \n        vertical_flip = False, \n        fill_mode = 'reflect')\n    \n    \n    # flow from directory with specified batch size\n    # and target image size\n    generator = image_generator.flow_from_dataframe(\n            dataframe=df,\n            directory=None,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=shuffle,\n            seed=seed,\n            target_size=(target_w,target_h))\n    \n    return generator\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:32.811117Z","iopub.execute_input":"2022-01-12T19:48:32.811504Z","iopub.status.idle":"2022-01-12T19:48:32.819159Z","shell.execute_reply.started":"2022-01-12T19:48:32.811455Z","shell.execute_reply":"2022-01-12T19:48:32.818431Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_test_and_valid_generator(valid_df, test_df, train_df, image_dir, x_col, y_cols, sample_size=100, batch_size=8, seed=1, target_w = 256, target_h = 256):\n\n    print(\"getting train and valid generators...\")\n    # get generator to sample dataset\n    raw_train_generator = ImageDataGenerator().flow_from_dataframe(\n        dataframe=train_df, \n        directory=image_dir, \n        x_col=\"img_ind\", \n        y_col=labels, \n        class_mode=\"raw\", \n        batch_size=sample_size, \n        shuffle=True, \n        target_size=(target_w, target_h))\n    \n    # get data sample\n    batch = raw_train_generator.next()\n    data_sample = batch[0]\n\n    # use sample to fit mean and std for test set generator\n    image_generator = ImageDataGenerator(\n        featurewise_center=True,\n        featurewise_std_normalization= True)\n    \n    # fit generator to sample from training data\n    image_generator.fit(data_sample)\n\n    # get test generator\n    valid_generator = image_generator.flow_from_dataframe(\n            dataframe=valid_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n\n    test_generator = image_generator.flow_from_dataframe(\n            dataframe=test_df,\n            directory=image_dir,\n            x_col=x_col,\n            y_col=y_cols,\n            class_mode=\"raw\",\n            batch_size=batch_size,\n            shuffle=False,\n            seed=seed,\n            target_size=(target_w,target_h))\n    return valid_generator, test_generator","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:32.820657Z","iopub.execute_input":"2022-01-12T19:48:32.820934Z","iopub.status.idle":"2022-01-12T19:48:32.832373Z","shell.execute_reply.started":"2022-01-12T19:48:32.820896Z","shell.execute_reply":"2022-01-12T19:48:32.831505Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_generator = get_train_generator(df = train_set,\n                                      image_dir = None, \n                                      x_col = \"img_ind\",\n                                      y_cols = labels, \n                                      batch_size=BATCH_SIZE,\n                                      target_w = IMAGE_SIZE[0], \n                                      target_h = IMAGE_SIZE[1] \n                                      )\n\nvalid_generator, test_generator= get_test_and_valid_generator(valid_df = valid_set, \n                                                              test_df = test_set, \n                                                              train_df = train_set,\n                                                              \n                                                              image_dir = None, \n                                                              x_col = \"img_ind\", \n                                                              y_cols = labels,\n                                                              batch_size = BATCH_SIZE,\n                                                              target_w = IMAGE_SIZE[0], \n                                                              target_h = IMAGE_SIZE[1])","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:32.834117Z","iopub.execute_input":"2022-01-12T19:48:32.834536Z","iopub.status.idle":"2022-01-12T19:48:44.802807Z","shell.execute_reply.started":"2022-01-12T19:48:32.834497Z","shell.execute_reply":"2022-01-12T19:48:44.802059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef get_label(y):\n\n    ret_labels = []\n    i = 0\n    for idx in y:\n        if idx:\n            ret_labels.append(labels[i])\n        i += 1\n    if not ret_labels:\n        return 'No Label'\n    else:\n        return '|'.join(ret_labels)\n\n#get one batch of images from the imageset    \nx, y = train_generator.__getitem__(0)\n\n\n# birkaç resmin sınıflarını başlık olarak üstüne yazdırma\nfig=plt.figure(figsize=(20, 10))\ncolumns = 4; rows =2 \nfor i in tqdm(range(1, columns*rows +1)):\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(x[i-1], cmap = 'gray')\n    plt.title(get_label(y[i-1]))\n    plt.axis(False)\n    fig.add_subplot","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:44.804176Z","iopub.execute_input":"2022-01-12T19:48:44.804443Z","iopub.status.idle":"2022-01-12T19:48:46.112836Z","shell.execute_reply.started":"2022-01-12T19:48:44.804407Z","shell.execute_reply":"2022-01-12T19:48:46.111207Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# sınıf dengesizliğini gösterdik. Her bir sınıfın yüzdelik frekansı\n# unbalanced yani dengesiz veri\nplt.figure(figsize=(8,4))\nplt.xticks(rotation = 90)\nplt.bar(labels, train_generator.labels.sum(axis = 0)/train_generator.n * 100)\nplt.title('Percentage ofdifferent conditions in train dataset')\nplt.xlabel('Conditions')\nplt.ylabel('Percentage')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:46.11383Z","iopub.execute_input":"2022-01-12T19:48:46.114174Z","iopub.status.idle":"2022-01-12T19:48:46.356491Z","shell.execute_reply.started":"2022-01-12T19:48:46.114121Z","shell.execute_reply":"2022-01-12T19:48:46.355829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def compute_class_freqs(labels):\n    \"\"\"\n    Compute positive and negative frequences for each class.\n\n    Args:\n        labels (np.array): matrix of labels, size (num_examples, num_classes)\n    Returns:\n        positive_frequencies (np.array): array of positive frequences for each\n                                         class, size (num_classes)\n        negative_frequencies (np.array): array of negative frequences for each\n                                         class, size (num_classes)\n    \"\"\"    \n    # total number of patients (rows)\n    N = labels.shape[0]\n    positive_frequencies = (labels.sum(axis = 0))/N\n    negative_frequencies = 1.0 - positive_frequencies\n    \n    return positive_frequencies, negative_frequencies\n\n\n# her satırda pozitif hastalık 1 olarak belirtiliyor ancak,\n# diğer 15 hastalık 0 olarak algılanınca modelde loss değeri\n# negatif sınıf tarafından ayarlanacak. \nfreq_pos, freq_neg = compute_class_freqs(train_generator.labels)\ndata = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": freq_pos})\ndata = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} for l,v in enumerate(freq_neg)], ignore_index=True)\nplt.xticks(rotation=90)\nf = sns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:46.357639Z","iopub.execute_input":"2022-01-12T19:48:46.358528Z","iopub.status.idle":"2022-01-12T19:48:46.883955Z","shell.execute_reply.started":"2022-01-12T19:48:46.358487Z","shell.execute_reply":"2022-01-12T19:48:46.883271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# bu durumun önüne geçip pozitif vakalar ile negatif olanların katkısını eşitlemek için\n# her sınıftan her örneği sınıfa özgü bir ağırlık faktörü ile çarparak bu durum elde edilir.\npos_weights = freq_neg\nneg_weights = freq_pos\npos_contribution = freq_pos * pos_weights \nneg_contribution = freq_neg * neg_weights\npos_weights\n\n\ndata = pd.DataFrame({\"Class\": labels, \"Label\": \"Positive\", \"Value\": pos_contribution})\ndata = data.append([{\"Class\": labels[l], \"Label\": \"Negative\", \"Value\": v} \n                        for l,v in enumerate(neg_contribution)], ignore_index=True)\nplt.xticks(rotation=90)\nsns.barplot(x=\"Class\", y=\"Value\", hue=\"Label\" ,data=data);","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:46.886095Z","iopub.execute_input":"2022-01-12T19:48:46.886591Z","iopub.status.idle":"2022-01-12T19:48:47.483926Z","shell.execute_reply.started":"2022-01-12T19:48:46.886552Z","shell.execute_reply":"2022-01-12T19:48:47.483268Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# her eğitim durumunda ağırlıklar hesaplandıktan sonra weighted loss değeri \n# aşağıdaki fonksiyonla bulunur.\ndef get_weighted_loss(pos_weights, neg_weights, epsilon=1e-7):\n    \"\"\"\n    Verilen negataif ve pozifif ağırlıklara göre ağırlıklı kayıp fonksiyonu döndürür.\n    Return weighted loss function given negative weights and positive weights.\n\n    parametreler:\n      pos_weights (np.array): Her sınıf için pozitif ağırlıklar dizisi\n      neg_weights (np.array): Her sınıf için negatif ağırlıklar dizisi\n    \n    dönüş:\n      weighted_loss : ağırlıklı loss değerini döndürür\n    \"\"\"\n    def weighted_loss(y_true, y_pred):\n        \"\"\"\n        ağırlıklı loss değerini döndürür\n\n        Args:\n            y_true (Tensor): verilen doğru etiketler,\n            y_pred (Tensor): öngörülen etiketler\n        Returns:\n            loss (Float): tüm sınıflardan toplanan kayıp değeri\n        \"\"\"\n        # loss değerini 0 ile başlattık\n        loss = 0.0\n        \n        for i in range(len(pos_weights)):\n            # her sınıf için, ortalama kayıp ağırlıklarını ekliyoruz\n \n            loss_pos = -1 * K.mean(pos_weights[i] * y_true[:, i] * K.log(y_pred[:, i] + epsilon))\n            loss_neg = -1 * K.mean(neg_weights[i] * (1 - y_true[:, i]) * K.log(1 - y_pred[:, i] + epsilon))\n            loss += loss_pos + loss_neg\n        return loss\n\n    return weighted_loss","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:47.48514Z","iopub.execute_input":"2022-01-12T19:48:47.487547Z","iopub.status.idle":"2022-01-12T19:48:47.494414Z","shell.execute_reply.started":"2022-01-12T19:48:47.487497Z","shell.execute_reply":"2022-01-12T19:48:47.493776Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Modeli oluşturuyoruz\nwith strategy.scope():\n    dnet121 = DenseNet121(input_shape=(*IMAGE_SIZE, 3),\n                          weights='imagenet',\n                          include_top=False )\n    dnet121.trainable = True\n\n    model_dnet121 = tf.keras.Sequential([ dnet121, \n                                         Layers.GlobalAveragePooling2D(), \n                                         Layers.Dense(len(labels), activation ='sigmoid') ])\n    model_dnet121.compile(optimizer='adam',\n                           loss = get_weighted_loss(pos_weights, neg_weights), \n                           metrics = ['accuracy'] )\n    model_dnet121.summary()\n","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:47.498218Z","iopub.execute_input":"2022-01-12T19:48:47.498542Z","iopub.status.idle":"2022-01-12T19:48:53.298782Z","shell.execute_reply.started":"2022-01-12T19:48:47.498505Z","shell.execute_reply":"2022-01-12T19:48:53.298066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_lrfn(lr_start=0.002, lr_max=0.1, \n               lr_min=0, lr_rampup_epochs=8, \n               lr_sustain_epochs=0, lr_exp_decay=.8):\n\n    def lrfn(epoch):\n        if epoch < lr_rampup_epochs:\n            lr = (lr_max - lr_start) / lr_rampup_epochs * epoch + lr_start\n        elif epoch < lr_rampup_epochs + lr_sustain_epochs:\n            lr = lr_max\n        else:\n            lr = (lr_max - lr_min) *\\\n                 lr_exp_decay**(epoch - lr_rampup_epochs\\\n                                - lr_sustain_epochs) + lr_min\n        return lr\n    return lrfn\n\nlrfn = build_lrfn()\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:53.299965Z","iopub.execute_input":"2022-01-12T19:48:53.300203Z","iopub.status.idle":"2022-01-12T19:48:53.307138Z","shell.execute_reply.started":"2022-01-12T19:48:53.300166Z","shell.execute_reply":"2022-01-12T19:48:53.306084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_vals_before = model_dnet121.predict_generator(test_generator, steps = len(test_generator))","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:48:53.308568Z","iopub.execute_input":"2022-01-12T19:48:53.309034Z","iopub.status.idle":"2022-01-12T19:49:07.857295Z","shell.execute_reply.started":"2022-01-12T19:48:53.308998Z","shell.execute_reply":"2022-01-12T19:49:07.856536Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_generator)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:49:07.858972Z","iopub.execute_input":"2022-01-12T19:49:07.859498Z","iopub.status.idle":"2022-01-12T19:49:07.865733Z","shell.execute_reply.started":"2022-01-12T19:49:07.859458Z","shell.execute_reply":"2022-01-12T19:49:07.86495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#  Modelin oluşturulması\nbase_model = DenseNet121(weights='imagenet', include_top=False)\n# base_model = DenseNet121(weights='../input/pretrained-model/pretrained_model.h5', include_top=False)\n\nx = base_model.output\n # add a global spatial average pooling layer\nx = GlobalAveragePooling2D()(x)\n\n # and a logistic layer\npredictions = Dense(len(labels), activation=\"sigmoid\")(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\nmodel.compile(optimizer='adam', loss=get_weighted_loss(pos_weights, neg_weights), metrics = ['accuracy'])\n## model.load_weights('../input/pretrained-model/pretrained_model.h5') You are trying to load a weight file containing 242 layers into a model with 241 layers.\npredicted_vals_before = model.predict_generator(test_generator, steps = len(test_generator))\n\n\n\nhistory = model.fit_generator(train_generator, \n                               validation_data=valid_generator,\n                               steps_per_epoch=len(train_generator), \n                               validation_steps=len(valid_generator), \n                               epochs = 20)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:49:07.867442Z","iopub.execute_input":"2022-01-12T19:49:07.86797Z","iopub.status.idle":"2022-01-12T19:55:34.128464Z","shell.execute_reply.started":"2022-01-12T19:49:07.867934Z","shell.execute_reply":"2022-01-12T19:55:34.127715Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_training(history, lw = 3):\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Accuracy vs Validation Accuracy')\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend(fontsize = 'x-large')\n    plt.show()\n\n    plt.figure(figsize=(10,6))\n    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n    plt.title('Training Loss vs Validation Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend(fontsize = 'x-large')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:55:34.13Z","iopub.execute_input":"2022-01-12T19:55:34.130326Z","iopub.status.idle":"2022-01-12T19:55:34.139084Z","shell.execute_reply.started":"2022-01-12T19:55:34.130283Z","shell.execute_reply":"2022-01-12T19:55:34.13828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_training(history)","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:55:34.140369Z","iopub.execute_input":"2022-01-12T19:55:34.140968Z","iopub.status.idle":"2022-01-12T19:55:34.540967Z","shell.execute_reply.started":"2022-01-12T19:55:34.140931Z","shell.execute_reply":"2022-01-12T19:55:34.540329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predicted_vals_after = model.predict_generator(test_generator, steps = len(test_generator))\nauc_rocs_before =get_roc_curve(labels, predicted_vals_before, test_generator, when = 'before training')\nauc_rocs_after = get_roc_curve(labels, predicted_vals_after, test_generator, when = 'after training')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:55:34.542066Z","iopub.execute_input":"2022-01-12T19:55:34.542308Z","iopub.status.idle":"2022-01-12T19:55:37.433885Z","shell.execute_reply.started":"2022-01-12T19:55:34.542274Z","shell.execute_reply":"2022-01-12T19:55:37.433247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ind = np.arange(len(labels))\nplt.figure(figsize=(15,7))\nwidth = 0.2       \nplt.bar(ind, auc_rocs_before , width, label='Before')\nplt.bar(ind + width, auc_rocs_after, width, label='After')\nplt.ylabel('AUROC value', fontsize = 16)\nplt.title('AUROC of each diagnosis before and after training', fontsize = 18)\nplt.xticks(ind + width / 2, labels, rotation = 90, fontsize = 14)\nplt.yticks(fontsize = 14)\nplt.legend(loc='best')\nplt.grid(True)\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:55:37.435095Z","iopub.execute_input":"2022-01-12T19:55:37.435604Z","iopub.status.idle":"2022-01-12T19:55:37.774074Z","shell.execute_reply.started":"2022-01-12T19:55:37.435564Z","shell.execute_reply":"2022-01-12T19:55:37.773443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('denseNet_trained_weights.h5')","metadata":{"execution":{"iopub.status.busy":"2022-01-12T19:55:37.775063Z","iopub.execute_input":"2022-01-12T19:55:37.775881Z","iopub.status.idle":"2022-01-12T19:55:39.171882Z","shell.execute_reply.started":"2022-01-12T19:55:37.775841Z","shell.execute_reply":"2022-01-12T19:55:39.170921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}